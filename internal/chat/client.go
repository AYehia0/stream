package chat

import (
	"context"
	"net/http"
)

const (
	baseURL = "https://api.groq.com/openai"
)

type GroqClient interface {
	SendMessage(ctx context.Context, req ChatRequest) (<-chan *ChatStreamResponse, func(), error)
}

// the DTOs for the Groq API
type ChatRequest struct {
	Messages       []Message `json:"messages"`                  // A list of messages comprising the conversation so far.
	Stream         bool      `json:"stream,omitempty"`          // If set, partial message deltas will be sent as data-only server-sent events
	Model          ModelID   `json:"model"`                     // The model to use for the chat completion.
	MaxTokens      int       `json:"max_tokens,omitempty"`      // The maximum number of tokens that can be generated in the chat completion.
	Temperature    float64   `json:"temperature,omitempty"`     // Sampling temperature
	TopP           float64   `json:"top_p,omitempty"`           // Nucleus sampling probability
	UserID         string    `json:"user,omitempty"`            // Unique identifier for the end-user
	ResponseFormat any       `json:"response_format,omitempty"` // Format of the model's response
	Seed           int       `json:"seed,omitempty"`            // Seed for deterministic sampling
}

// ChatCompletionResponse represents the response from the chat completion API.
type ChatResponse struct {
	ID      string   `json:"id"`      // Unique identifier for the completion
	Object  string   `json:"object"`  // Type of the object (e.g., "chat.completion")
	Created int64    `json:"created"` // Timestamp of creation
	Model   string   `json:"model"`   // ID of the model used
	Choices []Choice `json:"choices"` // List of completion choices
	Usage   Usage    `json:"usage"`   // Token usage information
}

// Choice represents a single completion choice returned by the chat completion API.
type Choice struct {
	Index        int     `json:"index"`         // Index of the choice
	Message      Message `json:"message"`       // Message generated by the model
	Delta        Message `json:"delta"`         // Partial generated message when you are streaming
	FinishReason string  `json:"finish_reason"` // Reason why the model stopped generating tokens
}

// Usage represents the token usage information in the chat completion response.
type Usage struct {
	PromptTokens     int     `json:"prompt_tokens"`     // Number of tokens in the prompt
	CompletionTokens int     `json:"completion_tokens"` // Number of tokens in the completion
	TotalTokens      int     `json:"total_tokens"`      // Total number of tokens
	PromptTime       float64 `json:"prompt_time"`       // Time taken for the prompt
	CompletionTime   float64 `json:"completion_time"`   // Time taken for the completion
	TotalTime        float64 `json:"total_time"`        // Total time taken
}

// the client is used to communicate with the Groq API
// it sends the user message and receives the assistant's response
type groqClient struct {
	BaseURL    string
	APIKey     string
	HTTPClient *http.Client
}

func NewGroqClient(apiKey string) *groqClient {
	return &groqClient{
		BaseURL:    baseURL,
		APIKey:     apiKey,
		HTTPClient: &http.Client{},
	}
}
